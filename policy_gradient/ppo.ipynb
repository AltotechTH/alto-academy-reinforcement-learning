{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# allow PyTorch throw errors as soon as a NaN gradient is detected\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# if GPU is to be used\n",
    "\"\"\" ref: M1 GPU support\n",
    "https://developer.apple.com/metal/pytorch/\n",
    "https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/\n",
    "\"\"\"\n",
    "_device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "_device_name = \"mps\" if torch.backends.mps.is_available() else _device_name\n",
    "device = torch.device(_device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MountainCar-Continuous Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Environment information\n",
    "ref: https://github.com/openai/gym/blob/master/gym/envs/classic_control/continuous_mountain_car.py#L27\n",
    "\n",
    "Observation Space\n",
    "    The observation is a `ndarray` with shape `(2,)` where the elements correspond to the following:\n",
    "    | Num | Observation                          | Min  | Max | Unit         |\n",
    "    |-----|--------------------------------------|------|-----|--------------|\n",
    "    | 0   | position of the car along the x-axis | -Inf | Inf | position (m) |\n",
    "    | 1   | velocity of the car                  | -Inf | Inf | position (m) |\n",
    "Action Space\n",
    "    The action is a `ndarray` with shape `(1,)`, representing the directional force applied on the car.\n",
    "    The action is clipped in the range `[-1,1]` and multiplied by a power of 0.0015.\n",
    "Reward\n",
    "    A negative reward of *-0.1 * action<sup>2</sup>* is received at each timestep to penalise for\n",
    "    taking actions of large magnitude. If the mountain car reaches the goal then a positive reward of +100\n",
    "    is added to the negative reward for that timestep.\n",
    "Starting State\n",
    "    The position of the car is assigned a uniform random value in `[-0.6 , -0.4]`.\n",
    "    The starting velocity of the car is always assigned to 0.\n",
    "Episode End\n",
    "    The episode ends if either of the following happens:\n",
    "    1. Termination: The position of the car is greater than or equal to 0.45 (the goal position on top of the right hill)\n",
    "    2. Truncation: The length of the episode is 999.\n",
    "\"\"\"\n",
    "env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "# env.reset()\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample environment image\n",
    "\n",
    "<img width=300 src=\"mountain_car.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.46703225,  0.        ],\n",
       "        [-0.46703225,  0.        ],\n",
       "        [-0.46703225,  0.        ],\n",
       "        [-0.46703225,  0.        ]], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class ConcatObs(gym.Wrapper):\n",
    "    def __init__(self, env, k, bound_value=1e6):\n",
    "        super().__init__(env)\n",
    "        self.k = k\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        # Use large finite values for bounds instead of infinity\n",
    "        self.observation_space = gym.spaces.Box(low=-bound_value, high=bound_value, shape=((k,) + shp), dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=123, options={\"low\": -1, \"high\": 0.3}):\n",
    "        ob, info = self.env.reset(options=options)\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(ob)\n",
    "        return self._get_ob(), info\n",
    "\n",
    "    def step(self, action):\n",
    "        ob, reward, done, _, info = self.env.step(action)\n",
    "        self.frames.append(ob)\n",
    "        return self._get_ob(), reward, done, False, info\n",
    "\n",
    "    def _get_ob(self):\n",
    "        return np.array(self.frames)\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "concat_env = ConcatObs(env, 4)\n",
    "concat_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space:  Box(-1000000.0, 1000000.0, (4, 2), float32)\n",
      "sample obs:  [[-0.8535572  0.       ]\n",
      " [-0.8535572  0.       ]\n",
      " [-0.8535572  0.       ]\n",
      " [-0.8535572  0.       ]]\n",
      "action_space:  Box(-1.0, 1.0, (1,), float32)\n",
      "sample action:  [-0.8062074]\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_space: \", concat_env.observation_space)\n",
    "\n",
    "obs, _ = concat_env.reset()  # set random initial position [-1, 0.3]\n",
    "print(\"sample obs: \", obs)\n",
    "\n",
    "print(\"action_space: \", concat_env.action_space)\n",
    "print(\"sample action: \", concat_env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PPO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 6520 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1156         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067263376 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.00735      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00662     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 0.0633       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 895         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009155652 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.0592      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0274     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 0.839       |\n",
      "|    value_loss           | 0.032       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 792          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015832088 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.00248      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.01         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 41.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 754          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032727453 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -1.15        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0132       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 0.797        |\n",
      "|    value_loss           | 0.107        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048745233 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    std                  | 0.788        |\n",
      "|    value_loss           | 41.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058663767 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.0842       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -6.42e-05    |\n",
      "|    std                  | 0.787        |\n",
      "|    value_loss           | 41.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004451313 |\n",
      "|    clip_fraction        | 0.0283      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6           |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    std                  | 0.785       |\n",
      "|    value_loss           | 79          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 704        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00443248 |\n",
      "|    clip_fraction        | 0.0345     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 80.5       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00162   |\n",
      "|    std                  | 0.784      |\n",
      "|    value_loss           | 134        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003575883 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    std                  | 0.784       |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038706341 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.6         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    std                  | 0.784        |\n",
      "|    value_loss           | 85.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041411063 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 79.4         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    std                  | 0.783        |\n",
      "|    value_loss           | 178          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032922383 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.1         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    std                  | 0.782        |\n",
      "|    value_loss           | 117          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 688          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061644297 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024734833 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.1         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.78         |\n",
      "|    value_loss           | 82.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 686          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023689652 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 61.1         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000673    |\n",
      "|    std                  | 0.778        |\n",
      "|    value_loss           | 81.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031755683 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 53.3         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    std                  | 0.776        |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060440693 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 0.000512     |\n",
      "|    std                  | 0.771        |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003502465 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00107    |\n",
      "|    std                  | 0.769       |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 681          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047791963 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    std                  | 0.768        |\n",
      "|    value_loss           | 67           |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 680           |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 63            |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081344834 |\n",
      "|    clip_fraction        | 0.00259       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.15         |\n",
      "|    explained_variance   | 0.783         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 18            |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000431     |\n",
      "|    std                  | 0.767         |\n",
      "|    value_loss           | 47.3          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 679          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020640716 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.2         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000914    |\n",
      "|    std                  | 0.766        |\n",
      "|    value_loss           | 51.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011862789 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.23         |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    std                  | 0.763        |\n",
      "|    value_loss           | 23.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002318889 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 0.759       |\n",
      "|    value_loss           | 60.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 675          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019443827 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.5         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    std                  | 0.758        |\n",
      "|    value_loss           | 43.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 674           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 78            |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083112076 |\n",
      "|    clip_fraction        | 0.0166        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.14         |\n",
      "|    explained_variance   | 0.883         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 10.4          |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | 0.000608      |\n",
      "|    std                  | 0.757         |\n",
      "|    value_loss           | 22.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 672          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024351354 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.751        |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 668           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 85            |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093845325 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.13         |\n",
      "|    explained_variance   | 0.917         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 14            |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.000576     |\n",
      "|    std                  | 0.741         |\n",
      "|    value_loss           | 19.5          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 666          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026007933 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.6         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    std                  | 0.739        |\n",
      "|    value_loss           | 56.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007573205 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.3         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00019     |\n",
      "|    std                  | 0.734        |\n",
      "|    value_loss           | 43.6         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 660           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 96            |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049559854 |\n",
      "|    clip_fraction        | 0.00464       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.11         |\n",
      "|    explained_variance   | 0.881         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 25.9          |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | 0.000115      |\n",
      "|    std                  | 0.729         |\n",
      "|    value_loss           | 73.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 659          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040411865 |\n",
      "|    clip_fraction        | 0.0434       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.5         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    std                  | 0.722        |\n",
      "|    value_loss           | 40.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058459817 |\n",
      "|    clip_fraction        | 0.0446       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.719        |\n",
      "|    value_loss           | 48.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004036548 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.000793   |\n",
      "|    std                  | 0.714       |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003413441 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024883924 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.702        |\n",
      "|    value_loss           | 39.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044253003 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.2         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.705        |\n",
      "|    value_loss           | 38.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 118          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052688103 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.1          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    std                  | 0.692        |\n",
      "|    value_loss           | 18.7         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 658           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 121           |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030530296 |\n",
      "|    clip_fraction        | 0.0112        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.05         |\n",
      "|    explained_variance   | 0.956         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 10.1          |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | 0.000341      |\n",
      "|    std                  | 0.687         |\n",
      "|    value_loss           | 38.1          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 659          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019616468 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.686        |\n",
      "|    value_loss           | 27.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001071824 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | 0.000322    |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 30.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017808554 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.46         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -5.97e-05    |\n",
      "|    std                  | 0.69         |\n",
      "|    value_loss           | 25.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052354923 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.3          |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000158    |\n",
      "|    std                  | 0.68         |\n",
      "|    value_loss           | 18.6         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 655       |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 137       |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0062846 |\n",
      "|    clip_fraction        | 0.049     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.04     |\n",
      "|    explained_variance   | 0.966     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 10.2      |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | -0.00275  |\n",
      "|    std                  | 0.684     |\n",
      "|    value_loss           | 26.5      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 655          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038475515 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.58         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.678        |\n",
      "|    value_loss           | 14.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023366585 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.45         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.000212    |\n",
      "|    std                  | 0.68         |\n",
      "|    value_loss           | 22.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040235734 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.05         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | 0.000869     |\n",
      "|    std                  | 0.682        |\n",
      "|    value_loss           | 17.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004039267 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.7         |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    std                  | 0.669       |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007005428 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.71        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    std                  | 0.66        |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x139060430>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (option 1) Train model\n",
    "\n",
    "# Create the original environment\n",
    "env = gym.make('MountainCarContinuous-v0')  #, render_mode=\"human\")\n",
    "# Wrap your environment with ConcatObs\n",
    "concat_env = ConcatObs(env, 4)\n",
    "# If you prefer to use a vectorized environment\n",
    "vec_env = DummyVecEnv([lambda: concat_env])\n",
    "\n",
    "# Initialize the PPO model using the wrapped environment\n",
    "model = PPO(\"MlpPolicy\", vec_env, verbose=1, gamma=0.99)\n",
    "\n",
    "total_timesteps = int(1e5)  # You can adjust this value according to your needs\n",
    "model.learn(total_timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (option 2) Train model with early stop\n",
    "env = make_vec_env('MountainCarContinuous-v0', n_envs=1)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model with early stopping\n",
    "total_timesteps = int(1e6)\n",
    "last_100_rewards = deque(maxlen=100)\n",
    "\n",
    "# Custom callback for early stopping\n",
    "def early_stopping_callback(_locals, _globals):\n",
    "    reward = _locals['rewards'][0]  # Adjust this if using more than one environment\n",
    "    last_100_rewards.append(reward)\n",
    "    \n",
    "    # Check for early stopping condition every 100 steps\n",
    "    if len(last_100_rewards) == 100 and np.mean(last_100_rewards) > 75.0:\n",
    "        print(\"Early stopping: Average reward of last 100 episodes is greater than 75.0\")\n",
    "        return False  # Returning False stops the training\n",
    "    return True  # Returning True continues the training\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps, callback=early_stopping_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained agent\n",
    "env = gym.make('MountainCarContinuous-v0', render_mode=\"human\")\n",
    "env = ConcatObs(env, 4)\n",
    "obs, _ = env.reset()\n",
    "for _ in range(1000):\n",
    "    obs = np.array(obs).astype(np.float32)\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, _, info = env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "    if dones:\n",
    "        break\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"ppo_mountaincarcontinuous\")\n",
    "\n",
    "# Load the trained model (optional, for demonstration here)\n",
    "_model = PPO.load(\"ppo_mountaincarcontinuous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
